{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import  Model\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization, Input, Bidirectional, GRU\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.signal import butter, lfilter\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def butter_highpass(cutoff, sampFreq, order=5):\n",
    "    nyquist = 0.5 * sampFreq\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    if normal_cutoff <= 0 or normal_cutoff >= 1:\n",
    "        raise ValueError(\"Cutoff frequency must be between 0 and Nyquist frequency\")\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass(cutoff, sampFreq, order=5):\n",
    "    nyquist = 0.5 * sampFreq\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    if normal_cutoff <= 0 or normal_cutoff >= 1:\n",
    "        raise ValueError(\"Cutoff frequency must be between 0 and Nyquist frequency\")\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def applyLowpassFilter(data, cutoff, sampFreq, filter_type='low', order=5):\n",
    "    if filter_type == 'low':\n",
    "        b, a = butter_lowpass(cutoff, sampFreq, order=order)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Use 'low' or 'high'.\")\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def applyHighpassFilter(data, cutoff, sampFreq, filter_type='high', order=5):\n",
    "    if filter_type == 'high':\n",
    "        b, a = butter_highpass(cutoff, sampFreq, order=order)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid filter type. Use 'low' or 'high'.\")\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "# Function to prepare data for LSTM input\n",
    "def prepare_data(chunk, timeStep):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    # Features and targets\n",
    "    x = chunk.iloc[:, 1:-2].values\n",
    "    arousal = chunk['Arousal Score'].values\n",
    "    anxiety = chunk['Anxiety Score'].values\n",
    "    \n",
    "    if np.isnan(arousal).any() or np.isnan(anxiety).any():\n",
    "        arousal = np.nan_to_num(arousal, nan=np.nanmean(arousal))\n",
    "        anxiety = np.nan_to_num(anxiety, nan=np.nanmean(anxiety))\n",
    "        \n",
    "    arousal = np.digitize(arousal, bins=[3, 6], right=True) \n",
    "    anxiety = np.digitize(anxiety, bins=[3, 6], right=True)\n",
    "    \n",
    "    #Low-High Pass filter\n",
    "    xFiltered = applyLowpassFilter(x, 63, 128,filter_type=\"low\")\n",
    "    xFiltered = applyHighpassFilter(xFiltered, 0.5, 128,filter_type=\"high\")\n",
    "    \n",
    "    xNormalised = scaler.fit_transform(xFiltered)\n",
    "    \n",
    "    xReshaped = np.array([xNormalised[i:i + timeStep] for i in range(len(xNormalised) - timeStep)], dtype=np.float32)\n",
    "    \n",
    "    arousalReshaped = to_categorical(arousal[timeStep:].astype(int), num_classes=3)\n",
    "    anxietyReshaped = to_categorical(anxiety[timeStep:].astype(int), num_classes=3)\n",
    "    \n",
    "     \n",
    "    return xReshaped, arousalReshaped, anxietyReshaped\n",
    "\n",
    "# Learning rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * 0.95 if epoch > 1 else lr\n",
    "\n",
    "# Function to train the model in chunks\n",
    "def chunkedTraining(model, outputFilePathS1, chunk_size, timeStep):\n",
    "    scheduler = LearningRateScheduler(lr_scheduler)\n",
    "    checkpoint = ModelCheckpoint('best_triclass_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Placeholder for validation and test data\n",
    "    xVal, arousalVal, anxietyVal = None, None, None\n",
    "    xTest, arousalTest, anxietyTest = None, None, None\n",
    "    \n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    train_arousal_accuracy_history = []\n",
    "    val_arousal_accuracy_history = []\n",
    "    train_anxiety_accuracy_history = []\n",
    "    val_anxiety_accuracy_history = []\n",
    "    \n",
    "    for i, chunk in enumerate(pd.read_csv(outputFilePathS1, chunksize=chunk_size)):\n",
    "        if i == 0:\n",
    "            # Split the first chunk into test, validation, and training sets\n",
    "            chunkTrain, chunkTemp = train_test_split(chunk, test_size=0.2)\n",
    "            chunkVal, chunkTest = train_test_split(chunkTemp, test_size=0.5)\n",
    "            \n",
    "            # Prepare validation data\n",
    "            xVal, arousalVal, anxietyVal = prepare_data(chunkVal, timeStep)\n",
    "            \n",
    "            # Prepare test data and save for later\n",
    "            xTest, arousalTest, anxietyTest = prepare_data(chunkTest, timeStep)\n",
    "            \n",
    "            chunk = chunkTrain\n",
    "            \n",
    "        \n",
    "        # Prepare training data\n",
    "        xTrain, arousalTrain, anxietyTrain = prepare_data(chunk, timeStep)\n",
    "        \n",
    "        arousalTrain = np.reshape(arousalTrain, (-1, 1))\n",
    "        anxietyTrain = np.reshape(anxietyTrain, (-1, 1))\n",
    "        arousalVal = np.reshape(arousalVal, (-1, 1))\n",
    "        anxietyVal = np.reshape(anxietyVal, (-1, 1))\n",
    "        # Skip empty chunks\n",
    "        if len(xTrain) == 0:\n",
    "            print(f\"Skipping empty chunk at index {i}.\")\n",
    "            continue\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(xTrain, \n",
    "                  {'arousal': arousalTrain, 'anxiety': anxietyTrain}, \n",
    "                  epochs=5, batch_size=64, verbose=1, \n",
    "                  validation_data=(xVal, \n",
    "                                   {'arousal': arousalVal, \n",
    "                                    'anxiety': anxietyVal}), \n",
    "                  callbacks=[scheduler, checkpoint])\n",
    "    \n",
    "        train_loss_history.extend(history.history['loss'])\n",
    "        val_loss_history.extend(history.history['val_loss'])\n",
    "        if 'arousal_accuracy' in history.history:\n",
    "            train_arousal_accuracy_history.extend(history.history['arousal_accuracy'])\n",
    "            val_arousal_accuracy_history.extend(history.history['val_arousal_accuracy'])\n",
    "\n",
    "        if 'anxiety_accuracy' in history.history:\n",
    "            train_anxiety_accuracy_history.extend(history.history['anxiety_accuracy'])\n",
    "            val_anxiety_accuracy_history.extend(history.history['val_anxiety_accuracy'])\n",
    "        \n",
    "    plt.figure(figsize= (10,6))    \n",
    "    plt.plot(train_loss_history, label = 'Training Loss')\n",
    "    plt.plot(val_loss_history, label = 'Validation Loss')\n",
    "    plt.title('Model Loss During Training')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Arousal Accuracy\n",
    "    if train_arousal_accuracy_history and val_arousal_accuracy_history:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_arousal_accuracy_history, label='Training Arousal Accuracy')\n",
    "        plt.plot(val_arousal_accuracy_history, label='Validation Arousal Accuracy')\n",
    "        plt.title('Arousal Accuracy Over Training')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "\n",
    "# Plotting Anxiety Accuracy\n",
    "    if train_anxiety_accuracy_history and val_anxiety_accuracy_history:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_anxiety_accuracy_history, label='Training Anxiety Accuracy')\n",
    "        plt.plot(val_anxiety_accuracy_history, label='Validation Anxiety Accuracy')\n",
    "        plt.title('Anxiety Accuracy Over Training')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "    # Return the model and the saved test data\n",
    "    return model, xTest, arousalTest, anxietyTest\n",
    "\n",
    "def evaluate_model(model, xTest, arousalTest, anxietyTest):\n",
    "    arousalTest = arousalTest.reshape(-1, 1)  # Reshape to (9872, 1)\n",
    "    anxietyTest = anxietyTest.reshape(-1, 1)\n",
    "    # Evaluate the model on the test data\n",
    "    results = model.evaluate(xTest, {'arousal': arousalTest, 'anxiety': anxietyTest}, verbose=1)\n",
    "    \n",
    "    # Print loss and accuracy\n",
    "    print(f\"Test Loss (Overall): {results[0]}\")\n",
    "    print(f\"Test Loss (Arousal): {results[1]}\")\n",
    "    print(f\"Test Loss (Anxiety): {results[2]}\")\n",
    "    print(f\"Test Accuracy (Arousal): {results[3]}\")\n",
    "    print(f\"Test Accuracy (Anxiety): {results[4]}\")\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.predict(xTest)\n",
    "    arousalPreds = predictions[0].argmax(axis=1) \n",
    "    anxietyPreds = predictions[1].argmax(axis=1)  \n",
    "\n",
    "    arousalTrue = arousalTest.argmax(axis=1)\n",
    "    anxietyTrue = anxietyTest.argmax(axis=1)\n",
    "    \n",
    "    # Classification reports for arousal and anxiety\n",
    "    print(\"\\nClassification Report for Arousal:\")\n",
    "    print(classification_report(arousalTrue, arousalPreds, target_names=['Low', 'Mid', 'High']))\n",
    "    \n",
    "    print(\"Classification Report for Anxiety:\")\n",
    "    print(classification_report(anxietyTrue, anxietyPreds, target_names=['Low', 'Mid', 'High']))\n",
    "\n",
    "    # Additional Metrics\n",
    "    print(f\"Arousal Accuracy: {accuracy_score(arousalTrue, arousalPreds)}\")\n",
    "    print(f\"Anxiety Accuracy: {accuracy_score(anxietyTrue, anxietyPreds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLstmModel(inputShape):\n",
    "    modelInput = Input(shape=inputShape)\n",
    "    \n",
    "    x = LSTM(128, return_sequences=True, kernel_regularizer='l2')(modelInput)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(128, return_sequences=True, kernel_regularizer='l2')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = LSTM(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "        \n",
    "    # Output layers\n",
    "    output_arousal = Dense(3, activation='softmax', name='arousal')(x)\n",
    "    output_anxiety = Dense(3, activation='softmax', name='anxiety')(x)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=modelInput, outputs=[output_arousal, output_anxiety])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss={'arousal': 'categorical_crossentropy', \n",
    "                        'anxiety': 'categorical_crossentropy'}, \n",
    "                  metrics={'arousal': ['accuracy'], 'anxiety': ['accuracy']})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "outputFilePathS1 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS1.csv'\n",
    "outputFilePathS2 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS2.csv'\n",
    "outputFilePathS3 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS3.csv'\n",
    "\n",
    "model = createLstmModel((timeStep, input_dim))\n",
    "model.summary()\n",
    "\n",
    "trainedLstmModel, xTest, arousalTest, anxietyTest = chunkedTraining(model, outputFilePathS1, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedLstmModel.summary()\n",
    "evaluate_model(trainedLstmModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedLstmModel, xTest, arousalTest, anxietyTest = chunkedTraining(trainedLstmModel, outputFilePathS2, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedLstmModel.summary()\n",
    "\n",
    "evaluate_model(trainedLstmModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedModelFull, xTest, arousalTest, anxietyTest = chunkedTraining(trainedLstmModel, outputFilePathS3, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModelFull.summary()\n",
    "\n",
    "evaluate_model(trainedModelFull, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainedLstmModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGruModel(inputShape):\n",
    "    modelInput = Input(shape=inputShape)\n",
    "    \n",
    "    x = GRU(128, return_sequences=True, kernel_regularizer='l2')(modelInput)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = GRU(128, return_sequences=True, kernel_regularizer='l2')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = GRU(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Output layers\n",
    "    output_arousal = Dense(3, activation='softmax', name='arousal')(x)\n",
    "    output_anxiety = Dense(3, activation='softmax', name='anxiety')(x)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=modelInput, outputs=[output_arousal, output_anxiety])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss={'arousal': 'categorical_crossentropy', \n",
    "                        'anxiety': 'categorical_crossentropy'}, \n",
    "                  metrics={'arousal': ['accuracy'], 'anxiety': ['accuracy']})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "outputFilePathS1 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS1.csv'\n",
    "outputFilePathS2 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS2.csv'\n",
    "outputFilePathS3 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS3.csv'\n",
    "\n",
    "model = createGruModel((timeStep, input_dim))\n",
    "model.summary()\n",
    "\n",
    "trainedGruModel, xTest, arousalTest, anxietyTest = chunkedTraining(model, outputFilePathS1, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedGruModel.summary()\n",
    "evaluate_model(trainedGruModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedGruModel, xTest, arousalTest, anxietyTest = chunkedTraining(trainedGruModel, outputFilePathS2, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedGruModel.summary()\n",
    "evaluate_model(trainedGruModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedGruModel, xTest, arousalTest, anxietyTest = chunkedTraining(trainedGruModel, outputFilePathS3, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedGruModel.summary()\n",
    "evaluate_model(trainedGruModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainedGruModel, xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBiLstmModel(inputShape):\n",
    "    modelInput = Input(shape=inputShape)\n",
    "    \n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer='l2'))(modelInput)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer='l2'))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Bidirectional(LSTM(64))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Output layers\n",
    "    output_arousal = Dense(3, activation='softmax', name='arousal')(x)\n",
    "    output_anxiety = Dense(3, activation='softmax', name='anxiety')(x)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs=modelInput, outputs=[output_arousal, output_anxiety])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss={'arousal': 'categorical_crossentropy', \n",
    "                        'anxiety': 'categorical_crossentropy'}, \n",
    "                  metrics={'arousal': ['accuracy'], 'anxiety': ['accuracy']})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "input_dim = 32\n",
    "chunk_size = 100000\n",
    "outputFilePathS1 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS1.csv'\n",
    "outputFilePathS2 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS2.csv'\n",
    "outputFilePathS3 = f'C:\\\\Users\\\\izaak\\Desktop\\\\VRETDataAnalysis\\\\Test 1\\\\totalRawWithLikertS3.csv'\n",
    "\n",
    "model = createBiLstmModel((timeStep, input_dim))\n",
    "model.summary()\n",
    "\n",
    "trainedBilstmModel, xTest, arousalTest, anxietyTest = chunkedTraining(model, outputFilePathS1, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedBilstmModel.summary()\n",
    "evaluate_model(trainedBilstmModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedBilstmModel, xTest, arousalTest, anxietyTest = chunkedTraining(trainedBilstmModel, outputFilePathS2, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedBilstmModel.summary()\n",
    "evaluate_model(trainedBilstmModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeStep = 128\n",
    "chunk_size = 100000\n",
    "\n",
    "trainedBilstmModel, xTest, arousalTest, anxietyTest = chunkedTraining(trainedBilstmModel, outputFilePathS3, chunk_size, timeStep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedBilstmModel.summary()\n",
    "evaluate_model(trainedBilstmModel, xTest, arousalTest, anxietyTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainedBilstmModel, xTest, arousalTest, anxietyTest \n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
